{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8486d0",
   "metadata": {},
   "source": [
    "# An Assortment of Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23311b97",
   "metadata": {},
   "source": [
    "### Data Analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2afa78c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def check_missing_data(df):\n",
    "    '''\n",
    "    Finds all columns with missing values. \n",
    "    If any columns are found, prints out each column and the percent of the column that is missing\n",
    "    '''\n",
    "    \n",
    "    missing_data = df.isnull().sum()\n",
    "    total_rows = len(df)\n",
    "    missing_columns = missing_data[missing_data > 0]\n",
    "    \n",
    "    if len(missing_columns) > 0:\n",
    "        print(\"Missing data found:\")\n",
    "        for column, count in missing_columns.items():\n",
    "            percent_missing = (count / total_rows) * 100\n",
    "            print(f\"Column '{column}': {count} missing values ({percent_missing:.2f}% of total)\")\n",
    "    else:\n",
    "        print(\"No missing data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_correlation_matrix(data):\n",
    "    '''\n",
    "    Plots a correlation matrix for all columns in the dataset\n",
    "    '''\n",
    "    \n",
    "    correlation_matrix = data.corr()\n",
    "\n",
    "    plt.figure(figsize=(14, 12))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    plt.title('Correlation Matrix - Titanic Dataset')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fe099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_unique_values(df, column_name):\n",
    "    '''\n",
    "    Prints out all unique values in column_name\n",
    "    '''\n",
    "    unique_values = df[column_name].unique()\n",
    "    print(f\"Unique values in column '{column_name}':\")\n",
    "    print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00110424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_col_distribution(df, column_name):\n",
    "    '''\n",
    "    plots a histogram for distribution of column_name\n",
    "    '''\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(df[column_name], bins=20, color='skyblue', edgecolor='black')  # Adjust the number of bins as needed\n",
    "    plt.title(f'Distribution of {column_name}')\n",
    "    plt.xlabel(column_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a94bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "def get_column_value_statistics(df, column_name):\n",
    "    '''\n",
    "    prints the following statistics for column_name:\n",
    "    mean, std(standard deviation), min, max,\n",
    "    IQR(5%, 25%, 75%, 90%, 95%, 99%)\n",
    "    '''\n",
    "    \n",
    "    column = df[column_name]\n",
    "    \n",
    "    statistics = {\n",
    "        \"mean\": column.mean(),\n",
    "        \"std\": column.std(),\n",
    "        \"min\": column.min(),\n",
    "        \"5%\": column.quantile(0.05),\n",
    "        \"25%\": column.quantile(0.25),\n",
    "        \"50%\": column.median(),\n",
    "        \"75%\": column.quantile(0.75),\n",
    "        \"90%\": column.quantile(0.90),\n",
    "        \"95%\": column.quantile(0.95),\n",
    "        \"99%\": column.quantile(0.99),\n",
    "        \"max\": column.max()\n",
    "    }\n",
    "    table = tabulate(statistics.items(), headers=[\"Statistic\", \"Value\"], tablefmt=\"plain\")\n",
    "\n",
    "    \n",
    "    print(f'{column_name} stats:\\n{table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_outliers(df, column_name, threshold=10):\n",
    "    column = df[column_name]\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - threshold * iqr\n",
    "    upper_bound = q3 + threshold * iqr\n",
    "    outliers = df[(column < lower_bound) | (column > upper_bound)][column_name].tolist()\n",
    "    \n",
    "    print(\"Outliers in column '{}':\".format(column_name))\n",
    "    print(outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6489e6",
   "metadata": {},
   "source": [
    "### Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54af824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column_name, threshold=10):\n",
    "    '''\n",
    "    Deletes all rows with outliers in column_name. \n",
    "    Warning: will delete the entire row even if the only outlier in that row is in column_name\n",
    "    '''\n",
    "    column = df[column_name]\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - threshold * iqr\n",
    "    upper_bound = q3 + threshold * iqr\n",
    "    df_no_outliers = df[(column >= lower_bound) & (column <= upper_bound)]\n",
    "    return df_no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65080aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_outliers(df, column_name, lower_pct=0.03, upper_pct=0.97):\n",
    "    '''\n",
    "    Sets all values outside the percentile ranges to the value at the lower and upper percentile\n",
    "    '''\n",
    "    \n",
    "    column = df[column_name]\n",
    "    lower_limit = column.quantile(lower_pct)\n",
    "    upper_limit = column.quantile(upper_pct)\n",
    "    winsorized_column = column.clip(lower=lower_limit, upper=upper_limit)\n",
    "    df_winsorized = df.copy()\n",
    "    df_winsorized[column_name] = winsorized_column\n",
    "    \n",
    "    return df_winsorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize2_outliers(df, column_name, lower_pct=0.01, upper_pct=0.99):\n",
    "    '''\n",
    "    Sets all values outside the percentile ranges to the value at the lower and upper percentile\n",
    "    '''\n",
    "    \n",
    "    column = df[column_name]\n",
    "    lower_limit = column.quantile(lower_pct)\n",
    "    upper_limit = column.quantile(upper_pct)\n",
    "    winsorized_column = column.clip(lower=lower_limit, upper=upper_limit)\n",
    "    df_winsorized = df.copy()\n",
    "    df_winsorized[column_name] = winsorized_column\n",
    "    \n",
    "    return df_winsorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_column(df, column_name, ranges, labels):\n",
    "    '''\n",
    "    Ranges in the form of: [element 1, element 2, ..., element n]\n",
    "    Bin generated in the form of: [min-element 1, element 2 - element 3,..., element n - max]\n",
    "    labels must be of length n + 1, where n is length of ranges. DO NOT USE STRINGS AS LABELS\n",
    "    '''\n",
    "    \n",
    "    # Define bins using the provided ranges\n",
    "    bins = [-float('inf')] + ranges + [float('inf')]\n",
    "    # Define labels for each range\n",
    "    bins_labels = labels\n",
    "    \n",
    "    # Discretize the column based on the defined bins and labels\n",
    "    df_discretized = df.copy()\n",
    "    df_discretized[column_name] = pd.cut(df[column_name], bins=bins, labels=bins_labels, include_lowest=True, right=False)\n",
    "    \n",
    "    return df_discretized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
